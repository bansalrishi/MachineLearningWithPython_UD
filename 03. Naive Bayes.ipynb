{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Its Naive(innocent) because it assumes that all the features are independent of each other. Which is almost never possible.  \n",
    "\n",
    "1. Easy to understand.  \n",
    "2. All features are independent.  \n",
    "3. All impact results equally.  \n",
    "4. Need small amount of data to train the model.  \n",
    "5. Fast – up to 100X faster.  \n",
    "6. It is highly scalable.  \n",
    "7. It can make probabilistic predictions.  \n",
    "8. It's simple & out-performs many sophisticated methods.  \n",
    "9. Stable to data changes.  \n",
    "\n",
    "\n",
    "## Bayes’s Theorem\n",
    "It describes the probability of an event, based on prior knowledge of conditions that might be related to the event.  \n",
    "\n",
    "$ P(A|B) = \\frac {P(B|A)*P(A)}{P(B)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose:  \n",
    "Fact_1 = 200 cars/day   \n",
    "Fact_2 = 300 cars/day  \n",
    "Out of all Cars produced: 2% are faulty/having issue\n",
    "Out of these faulty cars 50% came from each Factory.\n",
    "\n",
    "Question:\n",
    "What is the probability that a car manufactured by Fact_1 is faulty? P(Faulty | Fact_1)? \n",
    "\n",
    "Solution:  \n",
    "Car Manufctured by Factory 1: P(Fact_1) = $\\frac {200}{200 + 300} = 0.4$  \n",
    "Car Manufctured by Factory 2: P(Fact_2) = $\\frac {300}{200 + 300} = 0.6$  \n",
    "\n",
    "2% of cars are Faulty = P(Faulty) = 0.02\n",
    "\n",
    "Probability of a Faulty Car coming out of Factory 1: P(Fact_1 | Faulty) = 0.5  \n",
    "Probability of a Faulty Car coming out of Factory 2: P(Fact_2 | Faulty) = 0.5  \n",
    "\n",
    "\n",
    "P(Faulty | Fact_1) = $\\frac {P(Fact_1|Faulty)*P(Faulty)}{P(Fact_1)}  = \\frac{0.5*0.02}{0.4}$ = 2.5%\n",
    "\n",
    "Example:  \n",
    "Total 500 Cars  \n",
    "Fact_1 = 200  \n",
    "Fact_2 = 300  \n",
    "Faulty = 10  \n",
    "50% came froom Fact_1 = 5  \n",
    "% of Faulty Cars came from Fact_1 = $\\frac{5}{200}$ = 2.5%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd                 # pandas is a dataframe library\n",
    "import matplotlib.pyplot as plt      # matplotlib.pyplot plots data\n",
    "%matplotlib inline\n",
    "\n",
    "#Read the data\n",
    "df = pd.read_csv(\"Data/Classification/pima-data.csv\")\n",
    "\n",
    "#Check the Correlation\n",
    "df.corr()\n",
    "#Delete the correlated feature\n",
    "del df['skin']\n",
    "\n",
    "#Data Molding\n",
    "diabetes_map = {True : 1, False : 0}\n",
    "df['diabetes'] = df['diabetes'].map(diabetes_map)\n",
    "\n",
    "#Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#This will copy all columns from 0 to 7(8 - second place counts from 1)\n",
    "X = df.iloc[:, 0:8]\n",
    "y = df.iloc[:, 8]\n",
    "\n",
    "split_test_size = 0.30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_size, random_state=42) \n",
    "\n",
    "#Imputing\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "#Impute with mean all 0 readings\n",
    "fill_0 = SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "\n",
    "X_train = fill_0.fit_transform(X_train)\n",
    "X_test = fill_0.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training with Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create Gaussian Naive Bayes model object and train it with the data\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy on training data\n",
    "# predict values using the training data\n",
    "nb_predict_train = nb_model.predict(X_train)\n",
    "\n",
    "# import the performance metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, nb_predict_train)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7359\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy on test data\n",
    "# predict values using the testing data\n",
    "nb_predict_test = nb_model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# training metrics\n",
    "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, nb_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  33]\n",
      " [ 28  52]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       151\n",
      "           1       0.61      0.65      0.63        80\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       231\n",
      "   macro avg       0.71      0.72      0.71       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, nb_predict_test) )\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, nb_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pima-trained-model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  \n",
    "joblib.dump(nb_model, \"pima-trained-model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = joblib.load(\"pima-trained-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
